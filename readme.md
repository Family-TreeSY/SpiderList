#### 这段时间学习Python练手的爬虫集合

1. [链家爬虫](https://github.com/Family-TreeSY/SpiderList/tree/master/Lianjia)，数据存入了MongoDB数据库:[MongoDB学习笔记](https://family-treesy.github.io/2017/11/30/1.%20%E4%BB%80%E4%B9%88%E6%98%AFMongoDB%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%9F/)
2. [Scrapy爬取豆瓣TOP250电影](https://github.com/Family-TreeSY/SpiderList/tree/master/douban_movie)，这是一个简单的Scrapy入门爬虫
3. [Python爬取豆瓣小说](https://github.com/Family-TreeSY/SpiderList/tree/master/douban_reading)
4. [模拟登陆豆瓣](https://github.com/Family-TreeSY/SpiderList/tree/master/login_douban)
5. [模拟登陆GitHub](https://github.com/Family-TreeSY/SpiderList/tree/master/login_github)
6. [Scrapy爬取豆瓣TOP250]()，这是个Scrapy进阶学习，用正则定义爬取规则（CrawlRule）,将数据存入MongoDBpipeline项目管道
7. [爬取拉钩上海Python职位信息](https://github.com/Family-TreeSY/SpiderList/blob/master/lagou/lagou_spider.py)，这个爬虫让我简单了解了Ajax，算是长知识了！！
8. [爬取今日头条江歌案新闻信息](https://github.com/Family-TreeSY/SpiderList/blob/master/toutiao/toutiao_spider.py)
9. [猫眼TOP100电影](https://github.com/Family-TreeSY/SpiderList/blob/master/MaoyanTop100/MaoyanTop100.py)，增加了进程池实现了秒抓， - *-！！！！！！
10. [抓取电影芳华豆瓣影评](https://github.com/Family-TreeSY/SpiderList/blob/master/douban_fanghua/fanghua_spider.py)，这几天被芳华刷屏了，又没时间去电影院看，所以就爬取了芳华的影评假装当看了 ··········
11. [Scrapy爬取猫眼电影](https://github.com/Family-TreeSY/SpiderList/tree/master/maoyan)这个爬虫爬取效率很低！！我设置了delay，不设置么稍微一动就直接被封掉了，总共有23110页，每页有30条数据，总共693300条数据，就算不被ban掉，那得爬到猴年马月.................
![](http://m.qpic.cn/psb?/V10WDaE22S84Sl/YpE56Kh92bW7VYgfxOKF0xXwbjliiubEHdpLd3NizM8!/b/dPMAAAAAAAAA&bo=5AJ5AQAAAAADB7w!&rf=viewer_4)
是时候去学习scrapy-redis分布式爬虫了.....................................
12. [Scrapy-Redis分布式爬取自如网（一）](https://github.com/Family-TreeSY/SpiderList/blob/master/ziru/ziru/spiders/ziroom.py)，这几天学习了Scrapy-Redis分布式来提高爬取效率，也算是停留在舒适圈一段时间后往前走了一步！！

13. [Scrapy-Redis分布式抓取链家上海房源（二）](https://github.com/Family-TreeSY/Scrapy-Redis-Spider/tree/master/lianjia)

----------

[Scrapy-redis分布式爬虫](https://github.com/Family-TreeSY/Scrapy-Redis-Spider)

这个爬虫集合我会不定时更新以此来督促自己学习！亲们！假如喜欢点个star呗！！！互勉！！！！！！！！
